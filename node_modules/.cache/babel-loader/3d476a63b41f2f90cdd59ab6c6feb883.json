{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.MediatedLinkedRdfSourcesAsyncRdfIterator = void 0;\n\nconst stream_1 = require(\"stream\");\n\nconst LinkedRdfSourcesAsyncRdfIterator_1 = require(\"./LinkedRdfSourcesAsyncRdfIterator\");\n/**\n * An quad iterator that can iterate over consecutive RDF sources\n * that are determined using the rdf-resolve-hypermedia-links bus.\n *\n * @see LinkedRdfSourcesAsyncRdfIterator\n */\n\n\nclass MediatedLinkedRdfSourcesAsyncRdfIterator extends LinkedRdfSourcesAsyncRdfIterator_1.LinkedRdfSourcesAsyncRdfIterator {\n  constructor(cacheSize, context, forceSourceType, subject, predicate, object, graph, firstUrl, mediators) {\n    super(cacheSize, subject, predicate, object, graph, firstUrl);\n    this.context = context;\n    this.forceSourceType = forceSourceType;\n    this.mediatorRdfDereference = mediators.mediatorRdfDereference;\n    this.mediatorMetadata = mediators.mediatorMetadata;\n    this.mediatorMetadataExtract = mediators.mediatorMetadataExtract;\n    this.mediatorRdfResolveHypermedia = mediators.mediatorRdfResolveHypermedia;\n    this.mediatorRdfResolveHypermediaLinks = mediators.mediatorRdfResolveHypermediaLinks;\n    this.mediatorRdfResolveHypermediaLinksQueue = mediators.mediatorRdfResolveHypermediaLinksQueue;\n    this.handledUrls = {\n      [firstUrl]: true\n    };\n  }\n\n  getLinkQueue() {\n    if (!this.linkQueue) {\n      this.linkQueue = this.mediatorRdfResolveHypermediaLinksQueue.mediate({\n        firstUrl: this.firstUrl\n      }).then(result => result.linkQueue);\n    }\n\n    return this.linkQueue;\n  }\n\n  async getSourceLinks(metadata) {\n    try {\n      const {\n        urls\n      } = await this.mediatorRdfResolveHypermediaLinks.mediate({\n        context: this.context,\n        metadata\n      });\n      const links = urls.map(url => typeof url === 'string' ? {\n        url\n      } : url); // Filter URLs to avoid cyclic next-page loops\n\n      return links.filter(link => {\n        if (this.handledUrls[link.url]) {\n          return false;\n        }\n\n        this.handledUrls[link.url] = true;\n        return true;\n      });\n    } catch (_a) {\n      // No next URLs may be available, for example when we've reached the end of a Hydra next-page sequence.\n      return [];\n    }\n  }\n\n  async getSource(link, handledDatasets) {\n    // Include context entries from link\n    let context = this.context;\n\n    if (link.context) {\n      context = context.merge(link.context);\n    } // Get the RDF representation of the given document\n\n\n    let url = link.url;\n    let quads;\n    let metadata;\n\n    try {\n      const rdfDereferenceOutput = await this.mediatorRdfDereference.mediate({\n        context,\n        url\n      });\n      url = rdfDereferenceOutput.url; // Determine the metadata\n\n      const rdfMetadataOuput = await this.mediatorMetadata.mediate({\n        context,\n        url,\n        quads: rdfDereferenceOutput.quads,\n        triples: rdfDereferenceOutput.triples\n      });\n      metadata = (await this.mediatorMetadataExtract.mediate({\n        context,\n        url,\n        metadata: rdfMetadataOuput.metadata,\n        headers: rdfDereferenceOutput.headers\n      })).metadata;\n      quads = rdfMetadataOuput.data; // Optionally filter the resulting data\n\n      if (link.transform) {\n        quads = await link.transform(quads);\n      }\n    } catch (error) {\n      // Make sure that dereference errors are only emitted once an actor really needs the read quads\n      // This for example allows SPARQL endpoints that error on service description fetching to still be source-forcible\n      quads = new stream_1.Readable();\n\n      quads.read = () => {\n        quads.emit('error', error);\n        return null;\n      };\n\n      metadata = {};\n    } // Determine the source\n\n\n    const {\n      source,\n      dataset\n    } = await this.mediatorRdfResolveHypermedia.mediate({\n      context,\n      forceSourceType: this.forceSourceType,\n      handledDatasets,\n      metadata,\n      quads,\n      url\n    });\n\n    if (dataset) {\n      // Mark the dataset as applied\n      // This is needed to make sure that things like QPF search forms are only applied once,\n      // and next page links are followed after that.\n      handledDatasets[dataset] = true;\n    }\n\n    return {\n      link,\n      source,\n      metadata,\n      handledDatasets\n    };\n  }\n\n}\n\nexports.MediatedLinkedRdfSourcesAsyncRdfIterator = MediatedLinkedRdfSourcesAsyncRdfIterator;","map":{"version":3,"sources":["/Users/mark/localRepos/StarBrightlyShining/node_modules/@comunica/actor-rdf-resolve-quad-pattern-hypermedia/lib/MediatedLinkedRdfSourcesAsyncRdfIterator.js"],"names":["Object","defineProperty","exports","value","MediatedLinkedRdfSourcesAsyncRdfIterator","stream_1","require","LinkedRdfSourcesAsyncRdfIterator_1","LinkedRdfSourcesAsyncRdfIterator","constructor","cacheSize","context","forceSourceType","subject","predicate","object","graph","firstUrl","mediators","mediatorRdfDereference","mediatorMetadata","mediatorMetadataExtract","mediatorRdfResolveHypermedia","mediatorRdfResolveHypermediaLinks","mediatorRdfResolveHypermediaLinksQueue","handledUrls","getLinkQueue","linkQueue","mediate","then","result","getSourceLinks","metadata","urls","links","map","url","filter","link","_a","getSource","handledDatasets","merge","quads","rdfDereferenceOutput","rdfMetadataOuput","triples","headers","data","transform","error","Readable","read","emit","source","dataset"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,wCAAR,GAAmD,KAAK,CAAxD;;AACA,MAAMC,QAAQ,GAAGC,OAAO,CAAC,QAAD,CAAxB;;AACA,MAAMC,kCAAkC,GAAGD,OAAO,CAAC,oCAAD,CAAlD;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMF,wCAAN,SAAuDG,kCAAkC,CAACC,gCAA1F,CAA2H;AACvHC,EAAAA,WAAW,CAACC,SAAD,EAAYC,OAAZ,EAAqBC,eAArB,EAAsCC,OAAtC,EAA+CC,SAA/C,EAA0DC,MAA1D,EAAkEC,KAAlE,EAAyEC,QAAzE,EAAmFC,SAAnF,EAA8F;AACrG,UAAMR,SAAN,EAAiBG,OAAjB,EAA0BC,SAA1B,EAAqCC,MAArC,EAA6CC,KAA7C,EAAoDC,QAApD;AACA,SAAKN,OAAL,GAAeA,OAAf;AACA,SAAKC,eAAL,GAAuBA,eAAvB;AACA,SAAKO,sBAAL,GAA8BD,SAAS,CAACC,sBAAxC;AACA,SAAKC,gBAAL,GAAwBF,SAAS,CAACE,gBAAlC;AACA,SAAKC,uBAAL,GAA+BH,SAAS,CAACG,uBAAzC;AACA,SAAKC,4BAAL,GAAoCJ,SAAS,CAACI,4BAA9C;AACA,SAAKC,iCAAL,GAAyCL,SAAS,CAACK,iCAAnD;AACA,SAAKC,sCAAL,GAA8CN,SAAS,CAACM,sCAAxD;AACA,SAAKC,WAAL,GAAmB;AAAE,OAACR,QAAD,GAAY;AAAd,KAAnB;AACH;;AACDS,EAAAA,YAAY,GAAG;AACX,QAAI,CAAC,KAAKC,SAAV,EAAqB;AACjB,WAAKA,SAAL,GAAiB,KAAKH,sCAAL,CACZI,OADY,CACJ;AAAEX,QAAAA,QAAQ,EAAE,KAAKA;AAAjB,OADI,EAEZY,IAFY,CAEPC,MAAM,IAAIA,MAAM,CAACH,SAFV,CAAjB;AAGH;;AACD,WAAO,KAAKA,SAAZ;AACH;;AACmB,QAAdI,cAAc,CAACC,QAAD,EAAW;AAC3B,QAAI;AACA,YAAM;AAAEC,QAAAA;AAAF,UAAW,MAAM,KAAKV,iCAAL,CAAuCK,OAAvC,CAA+C;AAAEjB,QAAAA,OAAO,EAAE,KAAKA,OAAhB;AAAyBqB,QAAAA;AAAzB,OAA/C,CAAvB;AACA,YAAME,KAAK,GAAGD,IAAI,CAACE,GAAL,CAASC,GAAG,IAAI,OAAOA,GAAP,KAAe,QAAf,GAA0B;AAAEA,QAAAA;AAAF,OAA1B,GAAoCA,GAApD,CAAd,CAFA,CAGA;;AACA,aAAOF,KAAK,CAACG,MAAN,CAAaC,IAAI,IAAI;AACxB,YAAI,KAAKb,WAAL,CAAiBa,IAAI,CAACF,GAAtB,CAAJ,EAAgC;AAC5B,iBAAO,KAAP;AACH;;AACD,aAAKX,WAAL,CAAiBa,IAAI,CAACF,GAAtB,IAA6B,IAA7B;AACA,eAAO,IAAP;AACH,OANM,CAAP;AAOH,KAXD,CAYA,OAAOG,EAAP,EAAW;AACP;AACA,aAAO,EAAP;AACH;AACJ;;AACc,QAATC,SAAS,CAACF,IAAD,EAAOG,eAAP,EAAwB;AACnC;AACA,QAAI9B,OAAO,GAAG,KAAKA,OAAnB;;AACA,QAAI2B,IAAI,CAAC3B,OAAT,EAAkB;AACdA,MAAAA,OAAO,GAAGA,OAAO,CAAC+B,KAAR,CAAcJ,IAAI,CAAC3B,OAAnB,CAAV;AACH,KALkC,CAMnC;;;AACA,QAAIyB,GAAG,GAAGE,IAAI,CAACF,GAAf;AACA,QAAIO,KAAJ;AACA,QAAIX,QAAJ;;AACA,QAAI;AACA,YAAMY,oBAAoB,GAAG,MAAM,KAAKzB,sBAAL,CAC9BS,OAD8B,CACtB;AAAEjB,QAAAA,OAAF;AAAWyB,QAAAA;AAAX,OADsB,CAAnC;AAEAA,MAAAA,GAAG,GAAGQ,oBAAoB,CAACR,GAA3B,CAHA,CAIA;;AACA,YAAMS,gBAAgB,GAAG,MAAM,KAAKzB,gBAAL,CAAsBQ,OAAtB,CAA8B;AAAEjB,QAAAA,OAAF;AAAWyB,QAAAA,GAAX;AAAgBO,QAAAA,KAAK,EAAEC,oBAAoB,CAACD,KAA5C;AAAmDG,QAAAA,OAAO,EAAEF,oBAAoB,CAACE;AAAjF,OAA9B,CAA/B;AACAd,MAAAA,QAAQ,GAAG,CAAC,MAAM,KAAKX,uBAAL,CAA6BO,OAA7B,CAAqC;AACnDjB,QAAAA,OADmD;AAEnDyB,QAAAA,GAFmD;AAGnDJ,QAAAA,QAAQ,EAAEa,gBAAgB,CAACb,QAHwB;AAInDe,QAAAA,OAAO,EAAEH,oBAAoB,CAACG;AAJqB,OAArC,CAAP,EAKPf,QALJ;AAMAW,MAAAA,KAAK,GAAGE,gBAAgB,CAACG,IAAzB,CAZA,CAaA;;AACA,UAAIV,IAAI,CAACW,SAAT,EAAoB;AAChBN,QAAAA,KAAK,GAAG,MAAML,IAAI,CAACW,SAAL,CAAeN,KAAf,CAAd;AACH;AACJ,KAjBD,CAkBA,OAAOO,KAAP,EAAc;AACV;AACA;AACAP,MAAAA,KAAK,GAAG,IAAItC,QAAQ,CAAC8C,QAAb,EAAR;;AACAR,MAAAA,KAAK,CAACS,IAAN,GAAa,MAAM;AACfT,QAAAA,KAAK,CAACU,IAAN,CAAW,OAAX,EAAoBH,KAApB;AACA,eAAO,IAAP;AACH,OAHD;;AAIAlB,MAAAA,QAAQ,GAAG,EAAX;AACH,KArCkC,CAsCnC;;;AACA,UAAM;AAAEsB,MAAAA,MAAF;AAAUC,MAAAA;AAAV,QAAsB,MAAM,KAAKjC,4BAAL,CAAkCM,OAAlC,CAA0C;AACxEjB,MAAAA,OADwE;AAExEC,MAAAA,eAAe,EAAE,KAAKA,eAFkD;AAGxE6B,MAAAA,eAHwE;AAIxET,MAAAA,QAJwE;AAKxEW,MAAAA,KALwE;AAMxEP,MAAAA;AANwE,KAA1C,CAAlC;;AAQA,QAAImB,OAAJ,EAAa;AACT;AACA;AACA;AACAd,MAAAA,eAAe,CAACc,OAAD,CAAf,GAA2B,IAA3B;AACH;;AACD,WAAO;AAAEjB,MAAAA,IAAF;AAAQgB,MAAAA,MAAR;AAAgBtB,MAAAA,QAAhB;AAA0BS,MAAAA;AAA1B,KAAP;AACH;;AA7FsH;;AA+F3HvC,OAAO,CAACE,wCAAR,GAAmDA,wCAAnD","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.MediatedLinkedRdfSourcesAsyncRdfIterator = void 0;\nconst stream_1 = require(\"stream\");\nconst LinkedRdfSourcesAsyncRdfIterator_1 = require(\"./LinkedRdfSourcesAsyncRdfIterator\");\n/**\n * An quad iterator that can iterate over consecutive RDF sources\n * that are determined using the rdf-resolve-hypermedia-links bus.\n *\n * @see LinkedRdfSourcesAsyncRdfIterator\n */\nclass MediatedLinkedRdfSourcesAsyncRdfIterator extends LinkedRdfSourcesAsyncRdfIterator_1.LinkedRdfSourcesAsyncRdfIterator {\n    constructor(cacheSize, context, forceSourceType, subject, predicate, object, graph, firstUrl, mediators) {\n        super(cacheSize, subject, predicate, object, graph, firstUrl);\n        this.context = context;\n        this.forceSourceType = forceSourceType;\n        this.mediatorRdfDereference = mediators.mediatorRdfDereference;\n        this.mediatorMetadata = mediators.mediatorMetadata;\n        this.mediatorMetadataExtract = mediators.mediatorMetadataExtract;\n        this.mediatorRdfResolveHypermedia = mediators.mediatorRdfResolveHypermedia;\n        this.mediatorRdfResolveHypermediaLinks = mediators.mediatorRdfResolveHypermediaLinks;\n        this.mediatorRdfResolveHypermediaLinksQueue = mediators.mediatorRdfResolveHypermediaLinksQueue;\n        this.handledUrls = { [firstUrl]: true };\n    }\n    getLinkQueue() {\n        if (!this.linkQueue) {\n            this.linkQueue = this.mediatorRdfResolveHypermediaLinksQueue\n                .mediate({ firstUrl: this.firstUrl })\n                .then(result => result.linkQueue);\n        }\n        return this.linkQueue;\n    }\n    async getSourceLinks(metadata) {\n        try {\n            const { urls } = await this.mediatorRdfResolveHypermediaLinks.mediate({ context: this.context, metadata });\n            const links = urls.map(url => typeof url === 'string' ? { url } : url);\n            // Filter URLs to avoid cyclic next-page loops\n            return links.filter(link => {\n                if (this.handledUrls[link.url]) {\n                    return false;\n                }\n                this.handledUrls[link.url] = true;\n                return true;\n            });\n        }\n        catch (_a) {\n            // No next URLs may be available, for example when we've reached the end of a Hydra next-page sequence.\n            return [];\n        }\n    }\n    async getSource(link, handledDatasets) {\n        // Include context entries from link\n        let context = this.context;\n        if (link.context) {\n            context = context.merge(link.context);\n        }\n        // Get the RDF representation of the given document\n        let url = link.url;\n        let quads;\n        let metadata;\n        try {\n            const rdfDereferenceOutput = await this.mediatorRdfDereference\n                .mediate({ context, url });\n            url = rdfDereferenceOutput.url;\n            // Determine the metadata\n            const rdfMetadataOuput = await this.mediatorMetadata.mediate({ context, url, quads: rdfDereferenceOutput.quads, triples: rdfDereferenceOutput.triples });\n            metadata = (await this.mediatorMetadataExtract.mediate({\n                context,\n                url,\n                metadata: rdfMetadataOuput.metadata,\n                headers: rdfDereferenceOutput.headers,\n            })).metadata;\n            quads = rdfMetadataOuput.data;\n            // Optionally filter the resulting data\n            if (link.transform) {\n                quads = await link.transform(quads);\n            }\n        }\n        catch (error) {\n            // Make sure that dereference errors are only emitted once an actor really needs the read quads\n            // This for example allows SPARQL endpoints that error on service description fetching to still be source-forcible\n            quads = new stream_1.Readable();\n            quads.read = () => {\n                quads.emit('error', error);\n                return null;\n            };\n            metadata = {};\n        }\n        // Determine the source\n        const { source, dataset } = await this.mediatorRdfResolveHypermedia.mediate({\n            context,\n            forceSourceType: this.forceSourceType,\n            handledDatasets,\n            metadata,\n            quads,\n            url,\n        });\n        if (dataset) {\n            // Mark the dataset as applied\n            // This is needed to make sure that things like QPF search forms are only applied once,\n            // and next page links are followed after that.\n            handledDatasets[dataset] = true;\n        }\n        return { link, source, metadata, handledDatasets };\n    }\n}\nexports.MediatedLinkedRdfSourcesAsyncRdfIterator = MediatedLinkedRdfSourcesAsyncRdfIterator;\n//# sourceMappingURL=MediatedLinkedRdfSourcesAsyncRdfIterator.js.map"]},"metadata":{},"sourceType":"script"}