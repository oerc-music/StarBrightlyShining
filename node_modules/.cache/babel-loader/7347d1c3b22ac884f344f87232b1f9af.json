{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.JsonLdParser = void 0; // tslint:disable-next-line:no-var-requires\n\nconst Parser = require('jsonparse');\n\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n\nconst stream_1 = require(\"stream\");\n\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\n\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\n\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\n\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\n\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\n\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\n\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\n\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\n\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\n\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\n\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\n\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\n\nconst ParsingContext_1 = require(\"./ParsingContext\");\n\nconst Util_1 = require(\"./Util\");\n\nconst http_link_header_1 = require(\"http-link-header\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\n\n\nclass JsonLdParser extends stream_1.Transform {\n  constructor(options) {\n    super({\n      readableObjectMode: true\n    });\n    options = options || {};\n    this.options = options;\n    this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({\n      parser: this\n    }, options));\n    this.util = new Util_1.Util({\n      dataFactory: options.dataFactory,\n      parsingContext: this.parsingContext\n    });\n    this.jsonParser = new Parser();\n    this.contextJobs = [];\n    this.typeJobs = [];\n    this.contextAwaitingJobs = [];\n    this.lastDepth = 0;\n    this.lastKeys = [];\n    this.lastOnValueJob = Promise.resolve();\n    this.attachJsonParserListeners();\n  }\n  /**\n   * Construct a JsonLdParser from the given HTTP response.\n   *\n   * This will throw an error if no valid JSON response is received\n   * (application/ld+json, application/json, or something+json).\n   *\n   * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n   *\n   * This method is not responsible for handling redirects.\n   *\n   * @param baseIRI The URI of the received response.\n   * @param mediaType The received content type.\n   * @param headers Optional HTTP headers.\n   * @param options Optional parser options.\n   */\n\n\n  static fromHttpResponse(baseIRI, mediaType, headers, options) {\n    let context; // Special cases when receiving something else than the JSON-LD media type\n\n    if (mediaType !== 'application/ld+json') {\n      // Only accept JSON or JSON extension types\n      if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n        throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n      } // We need exactly one JSON-LD context in the link header\n\n\n      if (headers && headers.has('Link')) {\n        headers.forEach((value, key) => {\n          if (key === 'link') {\n            const linkHeader = http_link_header_1.parse(value);\n\n            for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n              if (context) {\n                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n              }\n\n              context = link.uri;\n            }\n          }\n        });\n      }\n\n      if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n        throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n      }\n    } // Check if the streaming profile is present\n\n\n    let streamingProfile;\n\n    if (headers && headers.has('Content-Type')) {\n      const contentType = headers.get('Content-Type');\n      const match = /; *profile=([^\"]*)/.exec(contentType);\n\n      if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n        streamingProfile = true;\n      }\n    }\n\n    return new JsonLdParser(Object.assign({\n      baseIRI,\n      context,\n      streamingProfile\n    }, options ? options : {}));\n  }\n  /**\n   * Parses the given text stream into a quad stream.\n   * @param {NodeJS.EventEmitter} stream A text stream.\n   * @return {RDF.Stream} A quad stream.\n   */\n\n\n  import(stream) {\n    const output = new stream_1.PassThrough({\n      readableObjectMode: true\n    });\n    stream.on('error', error => parsed.emit('error', error));\n    stream.on('data', data => output.push(data));\n    stream.on('end', () => output.push(null));\n    const parsed = output.pipe(new JsonLdParser(this.options));\n    return parsed;\n  }\n\n  _transform(chunk, encoding, callback) {\n    this.jsonParser.write(chunk);\n    this.lastOnValueJob.then(() => callback(), error => callback(error));\n  }\n  /**\n   * Start a new job for parsing the given value.\n   *\n   * This will let the first valid {@link IEntryHandler} handle the entry.\n   *\n   * @param {any[]} keys The stack of keys.\n   * @param value The value to parse.\n   * @param {number} depth The depth to parse at.\n   * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n   * @return {Promise<void>} A promise resolving when the job is done.\n   */\n\n\n  async newOnValueJob(keys, value, depth, lastDepthCheck) {\n    let flushStacks = true; // When we go up the stack, emit all unidentified values\n    // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n\n    if (lastDepthCheck && depth < this.lastDepth) {\n      // Check if we had any RDF lists that need to be terminated with an rdf:nil\n      const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n\n      if (listPointer) {\n        // Terminate the list if the had at least one value\n        if (listPointer.value) {\n          this.emit('data', this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n        } // Add the list id to the id stack, so it can be used higher up in the stack\n\n\n        listPointer.listId.listHead = true;\n        this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n        this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n      } // Flush the buffer for lastDepth\n      // If the parent key is a special type of container, postpone flushing until that parent is handled.\n\n\n      if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n        this.parsingContext.pendingContainerFlushBuffers.push({\n          depth: this.lastDepth,\n          keys: this.lastKeys.slice(0, this.lastKeys.length)\n        });\n        flushStacks = false;\n      } else {\n        await this.flushBuffer(this.lastDepth, this.lastKeys);\n      }\n    }\n\n    const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n    const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n    this.parsingContext.emittedStack[depth] = true;\n    let handleKey = true; // Keywords inside @reverse is not allowed\n\n    if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse') {\n      this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n    } // Skip further processing if one of the parent nodes are invalid.\n    // We use the validationStack to reuse validation results that were produced before with common key stacks.\n\n\n    let inProperty = false;\n\n    if (this.parsingContext.validationStack.length > 1) {\n      inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n    }\n\n    for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n      const validationResult = this.parsingContext.validationStack[i] || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n\n      if (!validationResult.valid) {\n        this.parsingContext.emittedStack[depth] = false;\n        handleKey = false;\n        break;\n      } else if (!inProperty && validationResult.property) {\n        inProperty = true;\n      }\n    } // Skip further processing if this node is part of a literal\n\n\n    if (this.util.isLiteral(depth)) {\n      handleKey = false;\n    } // Get handler\n\n\n    if (handleKey) {\n      for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n        const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n\n        if (testResult) {\n          // Pass processing over to the handler\n          await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult); // Flag that this depth is processed\n\n          if (entryHandler.isStackProcessor()) {\n            this.parsingContext.processingStack[depth] = true;\n          }\n\n          break;\n        }\n      }\n    } // Validate value indexes on the root.\n\n\n    if (depth === 0 && Array.isArray(value)) {\n      await this.util.validateValueIndexes(value);\n    } // When we go up the stack, flush the old stack\n\n\n    if (flushStacks && depth < this.lastDepth) {\n      // Reset our stacks\n      this.flushStacks(this.lastDepth);\n    }\n\n    this.lastDepth = depth;\n    this.lastKeys = keys; // Clear the keyword cache at this depth, and everything underneath.\n\n    this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n  }\n  /**\n   * Flush the processing stacks at the given depth.\n   * @param {number} depth A depth.\n   */\n\n\n  flushStacks(depth) {\n    this.parsingContext.processingStack.splice(depth, 1);\n    this.parsingContext.processingType.splice(depth, 1);\n    this.parsingContext.emittedStack.splice(depth, 1);\n    this.parsingContext.idStack.splice(depth, 1);\n    this.parsingContext.graphStack.splice(depth + 1, 1);\n    this.parsingContext.graphContainerTermStack.splice(depth, 1);\n    this.parsingContext.jsonLiteralStack.splice(depth, 1);\n    this.parsingContext.validationStack.splice(depth - 1, 2);\n    this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth); // TODO: just like the literal stack, splice all other stack until the end as well?\n  }\n  /**\n   * Flush buffers for the given depth.\n   *\n   * This should be called after the last entry at a given depth was processed.\n   *\n   * @param {number} depth A depth.\n   * @param {any[]} keys A stack of keys.\n   * @return {Promise<void>} A promise resolving if flushing is done.\n   */\n\n\n  async flushBuffer(depth, keys) {\n    let subjects = this.parsingContext.idStack[depth];\n\n    if (!subjects) {\n      subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n    } // Flush values at this level\n\n\n    const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n\n    if (valueBuffer) {\n      for (const subject of subjects) {\n        const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n        const graphs = this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0 ? this.parsingContext.idStack[depth - depthOffsetGraph - 1] : [await this.util.getGraphContainerValue(keys, depth)];\n\n        if (graphs) {\n          for (const graph of graphs) {\n            // Flush values to stream if the graph @id is known\n            this.parsingContext.emittedStack[depth] = true;\n\n            for (const bufferedValue of valueBuffer) {\n              if (bufferedValue.reverse) {\n                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.object, bufferedValue.predicate, subject, graph));\n              } else {\n                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(subject, bufferedValue.predicate, bufferedValue.object, graph));\n              }\n            }\n          }\n        } else {\n          // Place the values in the graphs buffer if the graph @id is not yet known\n          const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - (await this.util.getDepthOffsetGraph(depth, keys)) - 1);\n\n          for (const bufferedValue of valueBuffer) {\n            if (bufferedValue.reverse) {\n              subGraphBuffer.push({\n                object: subject,\n                predicate: bufferedValue.predicate,\n                subject: bufferedValue.object\n              });\n            } else {\n              subGraphBuffer.push({\n                object: bufferedValue.object,\n                predicate: bufferedValue.predicate,\n                subject\n              });\n            }\n          }\n        }\n      }\n\n      this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n      this.parsingContext.literalStack.splice(depth, 1);\n      this.parsingContext.jsonLiteralStack.splice(depth, 1);\n    } // Flush graphs at this level\n\n\n    const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n\n    if (graphBuffer) {\n      for (const subject of subjects) {\n        // A @graph statement at the root without @id relates to the default graph,\n        // unless there are top-level properties,\n        // others relate to blank nodes.\n        const graph = depth === 1 && subject.termType === 'BlankNode' && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n        this.parsingContext.emittedStack[depth] = true;\n\n        for (const bufferedValue of graphBuffer) {\n          this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n        }\n      }\n\n      this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n    }\n  }\n  /**\n   * Check if at least one {@link IEntryHandler} validates the entry to true.\n   * @param {any[]} keys A stack of keys.\n   * @param {number} depth A depth.\n   * @param {boolean} inProperty If the current depth is part of a valid property node.\n   * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n   */\n\n\n  async validateKey(keys, depth, inProperty) {\n    for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n      if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n        return {\n          valid: true,\n          property: inProperty || entryHandler.isPropertyHandler()\n        };\n      }\n    }\n\n    return {\n      valid: false,\n      property: false\n    };\n  }\n  /**\n   * Attach all required listeners to the JSON parser.\n   *\n   * This should only be called once.\n   */\n\n\n  attachJsonParserListeners() {\n    // Listen to json parser events\n    this.jsonParser.onValue = value => {\n      const depth = this.jsonParser.stack.length;\n      const keys = new Array(depth + 1).fill(0).map((v, i) => {\n        return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n      });\n\n      if (!this.isParsingContextInner(depth)) {\n        // Don't parse inner nodes inside @context\n        const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n\n        if (!this.parsingContext.streamingProfile && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n          // If an out-of-order context is allowed,\n          // we have to buffer everything.\n          // We store jobs for @context's and @type's separately,\n          // because at the end, we have to process them first.\n          // We also handle @type because these *could* introduce a type-scoped context.\n          if (keys[depth] === '@context') {\n            let jobs = this.contextJobs[depth];\n\n            if (!jobs) {\n              jobs = this.contextJobs[depth] = [];\n            }\n\n            jobs.push(valueJobCb);\n          } else if (keys[depth] === '@type' || typeof keys[depth] === 'number' && keys[depth - 1] === '@type') {\n            // Also capture @type with array values\n            // Remove @type from keys, because we want it to apply to parent later on\n            this.typeJobs.push({\n              job: valueJobCb,\n              keys: keys.slice(0, keys.length - 1)\n            });\n          } else {\n            this.contextAwaitingJobs.push({\n              job: valueJobCb,\n              keys\n            });\n          }\n        } else {\n          // Make sure that our value jobs are chained synchronously\n          this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n        } // Execute all buffered jobs on deeper levels\n\n\n        if (!this.parsingContext.streamingProfile && depth === 0) {\n          this.lastOnValueJob = this.lastOnValueJob.then(() => this.executeBufferedJobs());\n        }\n      }\n    };\n\n    this.jsonParser.onError = error => {\n      this.emit('error', error);\n    };\n  }\n  /**\n   * Check if the parser is currently parsing an element that is part of an @context entry.\n   * @param {number} depth A depth.\n   * @return {boolean} A boolean.\n   */\n\n\n  isParsingContextInner(depth) {\n    for (let i = depth; i > 0; i--) {\n      if (this.jsonParser.stack[i - 1].key === '@context') {\n        return true;\n      }\n    }\n\n    return false;\n  }\n  /**\n   * Execute all buffered jobs.\n   * @return {Promise<void>} A promise resolving if all jobs are finished.\n   */\n\n\n  async executeBufferedJobs() {\n    // Handle context jobs\n    for (const jobs of this.contextJobs) {\n      if (jobs) {\n        for (const job of jobs) {\n          await job();\n        }\n      }\n    } // Clear the keyword cache.\n\n\n    this.parsingContext.unaliasedKeywordCacheStack.splice(0); // Handle non-context jobs\n\n    for (const job of this.contextAwaitingJobs) {\n      // Check if we have a type (with possible type-scoped context) that should be handled before.\n      // We check all possible parent nodes for the current job, from root to leaves.\n      if (this.typeJobs.length > 0) {\n        // First collect all applicable type jobs\n        const applicableTypeJobs = [];\n        const applicableTypeJobIds = [];\n\n        for (let i = 0; i < this.typeJobs.length; i++) {\n          const typeJob = this.typeJobs[i];\n\n          if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n            applicableTypeJobs.push(typeJob);\n            applicableTypeJobIds.push(i);\n          }\n        } // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n\n\n        const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length); // Finally, execute the jobs in order\n\n        for (const typeJob of sortedTypeJobs) {\n          await typeJob.job();\n        } // Remove the executed type jobs\n        // Sort first, so we can efficiently splice\n\n\n        const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n\n        for (const jobId of sortedApplicableTypeJobIds) {\n          this.typeJobs.splice(jobId, 1);\n        }\n      }\n\n      await job.job();\n    }\n  }\n\n}\n\nexports.JsonLdParser = JsonLdParser;\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [new EntryHandlerArrayValue_1.EntryHandlerArrayValue(), new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(), new EntryHandlerKeywordId_1.EntryHandlerKeywordId(), new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(), new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(), new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(), new EntryHandlerKeywordType_1.EntryHandlerKeywordType(), new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(), new EntryHandlerContainer_1.EntryHandlerContainer(), new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(), new EntryHandlerPredicate_1.EntryHandlerPredicate(), new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback()];","map":{"version":3,"sources":["/Users/mark/localRepos/StarBrightlyShining/node_modules/jsonld-streaming-parser/lib/JsonLdParser.js"],"names":["Object","defineProperty","exports","value","JsonLdParser","Parser","require","jsonld_context_parser_1","stream_1","EntryHandlerArrayValue_1","EntryHandlerContainer_1","EntryHandlerInvalidFallback_1","EntryHandlerPredicate_1","EntryHandlerKeywordContext_1","EntryHandlerKeywordGraph_1","EntryHandlerKeywordId_1","EntryHandlerKeywordIncluded_1","EntryHandlerKeywordNest_1","EntryHandlerKeywordType_1","EntryHandlerKeywordUnknownFallback_1","EntryHandlerKeywordValue_1","ParsingContext_1","Util_1","http_link_header_1","Transform","constructor","options","readableObjectMode","parsingContext","ParsingContext","assign","parser","util","Util","dataFactory","jsonParser","contextJobs","typeJobs","contextAwaitingJobs","lastDepth","lastKeys","lastOnValueJob","Promise","resolve","attachJsonParserListeners","fromHttpResponse","baseIRI","mediaType","headers","context","endsWith","ErrorCoded","ERROR_CODES","LOADING_DOCUMENT_FAILED","has","forEach","key","linkHeader","parse","link","get","MULTIPLE_CONTEXT_LINK_HEADERS","uri","ignoreMissingContextLinkHeader","streamingProfile","contentType","match","exec","import","stream","output","PassThrough","on","error","parsed","emit","data","push","pipe","_transform","chunk","encoding","callback","write","then","newOnValueJob","keys","depth","lastDepthCheck","flushStacks","listPointer","listPointerStack","quad","rdfRest","rdfNil","getDefaultGraph","listId","listHead","idStack","listRootDepth","splice","EntryHandlerContainer","isBufferableContainerHandler","pendingContainerFlushBuffers","slice","length","flushBuffer","unaliasKeyword","parentKey","unaliasKeywordParent","emittedStack","handleKey","isValidKeyword","INVALID_REVERSE_PROPERTY_MAP","inProperty","validationStack","property","i","Math","max","validationResult","validateKey","valid","isLiteral","entryHandler","ENTRY_HANDLERS","testResult","test","handle","isStackProcessor","processingStack","Array","isArray","validateValueIndexes","unaliasedKeywordCacheStack","processingType","graphStack","graphContainerTermStack","jsonLiteralStack","literalStack","subjects","blankNode","valueBuffer","unidentifiedValuesBuffer","subject","depthOffsetGraph","getDepthOffsetGraph","graphs","getGraphContainerValue","graph","bufferedValue","reverse","emitQuad","object","predicate","subGraphBuffer","getUnidentifiedGraphBufferSafe","graphBuffer","unidentifiedGraphsBuffer","termType","topLevelProperties","validate","isPropertyHandler","onValue","stack","fill","map","v","isParsingContextInner","valueJobCb","contextTree","getContext","jobs","job","executeBufferedJobs","onError","applicableTypeJobs","applicableTypeJobIds","typeJob","isPrefixArray","sortedTypeJobs","sort","job1","job2","sortedApplicableTypeJobIds","jobId","DEFAULT_PROCESSING_MODE","EntryHandlerArrayValue","EntryHandlerKeywordContext","EntryHandlerKeywordId","EntryHandlerKeywordIncluded","EntryHandlerKeywordGraph","EntryHandlerKeywordNest","EntryHandlerKeywordType","EntryHandlerKeywordValue","EntryHandlerKeywordUnknownFallback","EntryHandlerPredicate","EntryHandlerInvalidFallback"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,YAAR,GAAuB,KAAK,CAA5B,C,CACA;;AACA,MAAMC,MAAM,GAAGC,OAAO,CAAC,WAAD,CAAtB;;AACA,MAAMC,uBAAuB,GAAGD,OAAO,CAAC,uBAAD,CAAvC;;AACA,MAAME,QAAQ,GAAGF,OAAO,CAAC,QAAD,CAAxB;;AACA,MAAMG,wBAAwB,GAAGH,OAAO,CAAC,uCAAD,CAAxC;;AACA,MAAMI,uBAAuB,GAAGJ,OAAO,CAAC,sCAAD,CAAvC;;AACA,MAAMK,6BAA6B,GAAGL,OAAO,CAAC,4CAAD,CAA7C;;AACA,MAAMM,uBAAuB,GAAGN,OAAO,CAAC,sCAAD,CAAvC;;AACA,MAAMO,4BAA4B,GAAGP,OAAO,CAAC,mDAAD,CAA5C;;AACA,MAAMQ,0BAA0B,GAAGR,OAAO,CAAC,iDAAD,CAA1C;;AACA,MAAMS,uBAAuB,GAAGT,OAAO,CAAC,8CAAD,CAAvC;;AACA,MAAMU,6BAA6B,GAAGV,OAAO,CAAC,oDAAD,CAA7C;;AACA,MAAMW,yBAAyB,GAAGX,OAAO,CAAC,gDAAD,CAAzC;;AACA,MAAMY,yBAAyB,GAAGZ,OAAO,CAAC,gDAAD,CAAzC;;AACA,MAAMa,oCAAoC,GAAGb,OAAO,CAAC,2DAAD,CAApD;;AACA,MAAMc,0BAA0B,GAAGd,OAAO,CAAC,iDAAD,CAA1C;;AACA,MAAMe,gBAAgB,GAAGf,OAAO,CAAC,kBAAD,CAAhC;;AACA,MAAMgB,MAAM,GAAGhB,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAMiB,kBAAkB,GAAGjB,OAAO,CAAC,kBAAD,CAAlC;AACA;AACA;AACA;;;AACA,MAAMF,YAAN,SAA2BI,QAAQ,CAACgB,SAApC,CAA8C;AAC1CC,EAAAA,WAAW,CAACC,OAAD,EAAU;AACjB,UAAM;AAAEC,MAAAA,kBAAkB,EAAE;AAAtB,KAAN;AACAD,IAAAA,OAAO,GAAGA,OAAO,IAAI,EAArB;AACA,SAAKA,OAAL,GAAeA,OAAf;AACA,SAAKE,cAAL,GAAsB,IAAIP,gBAAgB,CAACQ,cAArB,CAAoC7B,MAAM,CAAC8B,MAAP,CAAc;AAAEC,MAAAA,MAAM,EAAE;AAAV,KAAd,EAAgCL,OAAhC,CAApC,CAAtB;AACA,SAAKM,IAAL,GAAY,IAAIV,MAAM,CAACW,IAAX,CAAgB;AAAEC,MAAAA,WAAW,EAAER,OAAO,CAACQ,WAAvB;AAAoCN,MAAAA,cAAc,EAAE,KAAKA;AAAzD,KAAhB,CAAZ;AACA,SAAKO,UAAL,GAAkB,IAAI9B,MAAJ,EAAlB;AACA,SAAK+B,WAAL,GAAmB,EAAnB;AACA,SAAKC,QAAL,GAAgB,EAAhB;AACA,SAAKC,mBAAL,GAA2B,EAA3B;AACA,SAAKC,SAAL,GAAiB,CAAjB;AACA,SAAKC,QAAL,GAAgB,EAAhB;AACA,SAAKC,cAAL,GAAsBC,OAAO,CAACC,OAAR,EAAtB;AACA,SAAKC,yBAAL;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAC2B,SAAhBC,gBAAgB,CAACC,OAAD,EAAUC,SAAV,EAAqBC,OAArB,EAA8BtB,OAA9B,EAAuC;AAC1D,QAAIuB,OAAJ,CAD0D,CAE1D;;AACA,QAAIF,SAAS,KAAK,qBAAlB,EAAyC;AACrC;AACA,UAAIA,SAAS,KAAK,kBAAd,IAAoC,CAACA,SAAS,CAACG,QAAV,CAAmB,OAAnB,CAAzC,EAAsE;AAClE,cAAM,IAAI3C,uBAAuB,CAAC4C,UAA5B,CAAwC,kCAAiCJ,SAAU,EAAnF,EAAsFxC,uBAAuB,CAAC6C,WAAxB,CAAoCC,uBAA1H,CAAN;AACH,OAJoC,CAKrC;;;AACA,UAAIL,OAAO,IAAIA,OAAO,CAACM,GAAR,CAAY,MAAZ,CAAf,EAAoC;AAChCN,QAAAA,OAAO,CAACO,OAAR,CAAgB,CAACpD,KAAD,EAAQqD,GAAR,KAAgB;AAC5B,cAAIA,GAAG,KAAK,MAAZ,EAAoB;AAChB,kBAAMC,UAAU,GAAGlC,kBAAkB,CAACmC,KAAnB,CAAyBvD,KAAzB,CAAnB;;AACA,iBAAK,MAAMwD,IAAX,IAAmBF,UAAU,CAACG,GAAX,CAAe,KAAf,EAAsB,sCAAtB,CAAnB,EAAkF;AAC9E,kBAAIX,OAAJ,EAAa;AACT,sBAAM,IAAI1C,uBAAuB,CAAC4C,UAA5B,CAAuC,yDAAyDL,OAAhG,EAAyGvC,uBAAuB,CAAC6C,WAAxB,CAAoCS,6BAA7I,CAAN;AACH;;AACDZ,cAAAA,OAAO,GAAGU,IAAI,CAACG,GAAf;AACH;AACJ;AACJ,SAVD;AAWH;;AACD,UAAI,CAACb,OAAD,IAAY,EAAEvB,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAK,KAAK,CAArC,GAAyC,KAAK,CAA9C,GAAkDA,OAAO,CAACqC,8BAA5D,CAAhB,EAA6G;AACzG,cAAM,IAAIxD,uBAAuB,CAAC4C,UAA5B,CAAwC,8CAA6CJ,SAAU,OAAMD,OAAQ,EAA7G,EAAgHvC,uBAAuB,CAAC6C,WAAxB,CAAoCC,uBAApJ,CAAN;AACH;AACJ,KAzByD,CA0B1D;;;AACA,QAAIW,gBAAJ;;AACA,QAAIhB,OAAO,IAAIA,OAAO,CAACM,GAAR,CAAY,cAAZ,CAAf,EAA4C;AACxC,YAAMW,WAAW,GAAGjB,OAAO,CAACY,GAAR,CAAY,cAAZ,CAApB;AACA,YAAMM,KAAK,GAAG,qBAAqBC,IAArB,CAA0BF,WAA1B,CAAd;;AACA,UAAIC,KAAK,IAAIA,KAAK,CAAC,CAAD,CAAL,KAAa,wCAA1B,EAAoE;AAChEF,QAAAA,gBAAgB,GAAG,IAAnB;AACH;AACJ;;AACD,WAAO,IAAI5D,YAAJ,CAAiBJ,MAAM,CAAC8B,MAAP,CAAc;AAAEgB,MAAAA,OAAF;AAClCG,MAAAA,OADkC;AAElCe,MAAAA;AAFkC,KAAd,EAEAtC,OAAO,GAAGA,OAAH,GAAa,EAFpB,CAAjB,CAAP;AAGH;AACD;AACJ;AACA;AACA;AACA;;;AACI0C,EAAAA,MAAM,CAACC,MAAD,EAAS;AACX,UAAMC,MAAM,GAAG,IAAI9D,QAAQ,CAAC+D,WAAb,CAAyB;AAAE5C,MAAAA,kBAAkB,EAAE;AAAtB,KAAzB,CAAf;AACA0C,IAAAA,MAAM,CAACG,EAAP,CAAU,OAAV,EAAoBC,KAAD,IAAWC,MAAM,CAACC,IAAP,CAAY,OAAZ,EAAqBF,KAArB,CAA9B;AACAJ,IAAAA,MAAM,CAACG,EAAP,CAAU,MAAV,EAAmBI,IAAD,IAAUN,MAAM,CAACO,IAAP,CAAYD,IAAZ,CAA5B;AACAP,IAAAA,MAAM,CAACG,EAAP,CAAU,KAAV,EAAiB,MAAMF,MAAM,CAACO,IAAP,CAAY,IAAZ,CAAvB;AACA,UAAMH,MAAM,GAAGJ,MAAM,CAACQ,IAAP,CAAY,IAAI1E,YAAJ,CAAiB,KAAKsB,OAAtB,CAAZ,CAAf;AACA,WAAOgD,MAAP;AACH;;AACDK,EAAAA,UAAU,CAACC,KAAD,EAAQC,QAAR,EAAkBC,QAAlB,EAA4B;AAClC,SAAK/C,UAAL,CAAgBgD,KAAhB,CAAsBH,KAAtB;AACA,SAAKvC,cAAL,CACK2C,IADL,CACU,MAAMF,QAAQ,EADxB,EAC6BT,KAAD,IAAWS,QAAQ,CAACT,KAAD,CAD/C;AAEH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACuB,QAAbY,aAAa,CAACC,IAAD,EAAOnF,KAAP,EAAcoF,KAAd,EAAqBC,cAArB,EAAqC;AACpD,QAAIC,WAAW,GAAG,IAAlB,CADoD,CAEpD;AACA;;AACA,QAAID,cAAc,IAAID,KAAK,GAAG,KAAKhD,SAAnC,EAA8C;AAC1C;AACA,YAAMmD,WAAW,GAAG,KAAK9D,cAAL,CAAoB+D,gBAApB,CAAqC,KAAKpD,SAA1C,CAApB;;AACA,UAAImD,WAAJ,EAAiB;AACb;AACA,YAAIA,WAAW,CAACvF,KAAhB,EAAuB;AACnB,eAAKwE,IAAL,CAAU,MAAV,EAAkB,KAAK3C,IAAL,CAAUE,WAAV,CAAsB0D,IAAtB,CAA2BF,WAAW,CAACvF,KAAvC,EAA8C,KAAK6B,IAAL,CAAU6D,OAAxD,EAAiE,KAAK7D,IAAL,CAAU8D,MAA3E,EAAmF,KAAK9D,IAAL,CAAU+D,eAAV,EAAnF,CAAlB;AACH,SAJY,CAKb;;;AACAL,QAAAA,WAAW,CAACM,MAAZ,CAAmBC,QAAnB,GAA8B,IAA9B;AACA,aAAKrE,cAAL,CAAoBsE,OAApB,CAA4BR,WAAW,CAACS,aAAZ,GAA4B,CAAxD,IAA6D,CAACT,WAAW,CAACM,MAAb,CAA7D;AACA,aAAKpE,cAAL,CAAoB+D,gBAApB,CAAqCS,MAArC,CAA4C,KAAK7D,SAAjD,EAA4D,CAA5D;AACH,OAZyC,CAa1C;AACA;;;AACA,UAAI,MAAM7B,uBAAuB,CAAC2F,qBAAxB,CAA8CC,4BAA9C,CAA2E,KAAK1E,cAAhF,EAAgG,KAAKY,QAArG,EAA+G,KAAKD,SAApH,CAAV,EAA0I;AACtI,aAAKX,cAAL,CAAoB2E,4BAApB,CACK1B,IADL,CACU;AAAEU,UAAAA,KAAK,EAAE,KAAKhD,SAAd;AAAyB+C,UAAAA,IAAI,EAAE,KAAK9C,QAAL,CAAcgE,KAAd,CAAoB,CAApB,EAAuB,KAAKhE,QAAL,CAAciE,MAArC;AAA/B,SADV;AAEAhB,QAAAA,WAAW,GAAG,KAAd;AACH,OAJD,MAKK;AACD,cAAM,KAAKiB,WAAL,CAAiB,KAAKnE,SAAtB,EAAiC,KAAKC,QAAtC,CAAN;AACH;AACJ;;AACD,UAAMgB,GAAG,GAAG,MAAM,KAAKxB,IAAL,CAAU2E,cAAV,CAAyBrB,IAAI,CAACC,KAAD,CAA7B,EAAsCD,IAAtC,EAA4CC,KAA5C,CAAlB;AACA,UAAMqB,SAAS,GAAG,MAAM,KAAK5E,IAAL,CAAU6E,oBAAV,CAA+BvB,IAA/B,EAAqCC,KAArC,CAAxB;AACA,SAAK3D,cAAL,CAAoBkF,YAApB,CAAiCvB,KAAjC,IAA0C,IAA1C;AACA,QAAIwB,SAAS,GAAG,IAAhB,CA/BoD,CAgCpD;;AACA,QAAIxG,uBAAuB,CAAC0B,IAAxB,CAA6B+E,cAA7B,CAA4CxD,GAA5C,KAAoDoD,SAAS,KAAK,UAAtE,EAAkF;AAC9E,WAAKjC,IAAL,CAAU,OAAV,EAAmB,IAAIpE,uBAAuB,CAAC4C,UAA5B,CAAwC,kBAAiBhD,KAAM,+BAA/D,EAA+FI,uBAAuB,CAAC6C,WAAxB,CAAoC6D,4BAAnI,CAAnB;AACH,KAnCmD,CAoCpD;AACA;;;AACA,QAAIC,UAAU,GAAG,KAAjB;;AACA,QAAI,KAAKtF,cAAL,CAAoBuF,eAApB,CAAoCV,MAApC,GAA6C,CAAjD,EAAoD;AAChDS,MAAAA,UAAU,GAAG,KAAKtF,cAAL,CAAoBuF,eAApB,CAAoC,KAAKvF,cAAL,CAAoBuF,eAApB,CAAoCV,MAApC,GAA6C,CAAjF,EAAoFW,QAAjG;AACH;;AACD,SAAK,IAAIC,CAAC,GAAGC,IAAI,CAACC,GAAL,CAAS,CAAT,EAAY,KAAK3F,cAAL,CAAoBuF,eAApB,CAAoCV,MAApC,GAA6C,CAAzD,CAAb,EAA0EY,CAAC,GAAG/B,IAAI,CAACmB,MAAL,GAAc,CAA5F,EAA+FY,CAAC,EAAhG,EAAoG;AAChG,YAAMG,gBAAgB,GAAG,KAAK5F,cAAL,CAAoBuF,eAApB,CAAoCE,CAApC,MACjB,KAAKzF,cAAL,CAAoBuF,eAApB,CAAoCE,CAApC,IAAyC,MAAM,KAAKI,WAAL,CAAiBnC,IAAI,CAACkB,KAAL,CAAW,CAAX,EAAca,CAAC,GAAG,CAAlB,CAAjB,EAAuCA,CAAvC,EAA0CH,UAA1C,CAD9B,CAAzB;;AAEA,UAAI,CAACM,gBAAgB,CAACE,KAAtB,EAA6B;AACzB,aAAK9F,cAAL,CAAoBkF,YAApB,CAAiCvB,KAAjC,IAA0C,KAA1C;AACAwB,QAAAA,SAAS,GAAG,KAAZ;AACA;AACH,OAJD,MAKK,IAAI,CAACG,UAAD,IAAeM,gBAAgB,CAACJ,QAApC,EAA8C;AAC/CF,QAAAA,UAAU,GAAG,IAAb;AACH;AACJ,KArDmD,CAsDpD;;;AACA,QAAI,KAAKlF,IAAL,CAAU2F,SAAV,CAAoBpC,KAApB,CAAJ,EAAgC;AAC5BwB,MAAAA,SAAS,GAAG,KAAZ;AACH,KAzDmD,CA0DpD;;;AACA,QAAIA,SAAJ,EAAe;AACX,WAAK,MAAMa,YAAX,IAA2BxH,YAAY,CAACyH,cAAxC,EAAwD;AACpD,cAAMC,UAAU,GAAG,MAAMF,YAAY,CAACG,IAAb,CAAkB,KAAKnG,cAAvB,EAAuC,KAAKI,IAA5C,EAAkDwB,GAAlD,EAAuD8B,IAAvD,EAA6DC,KAA7D,CAAzB;;AACA,YAAIuC,UAAJ,EAAgB;AACZ;AACA,gBAAMF,YAAY,CAACI,MAAb,CAAoB,KAAKpG,cAAzB,EAAyC,KAAKI,IAA9C,EAAoDwB,GAApD,EAAyD8B,IAAzD,EAA+DnF,KAA/D,EAAsEoF,KAAtE,EAA6EuC,UAA7E,CAAN,CAFY,CAGZ;;AACA,cAAIF,YAAY,CAACK,gBAAb,EAAJ,EAAqC;AACjC,iBAAKrG,cAAL,CAAoBsG,eAApB,CAAoC3C,KAApC,IAA6C,IAA7C;AACH;;AACD;AACH;AACJ;AACJ,KAxEmD,CAyEpD;;;AACA,QAAIA,KAAK,KAAK,CAAV,IAAe4C,KAAK,CAACC,OAAN,CAAcjI,KAAd,CAAnB,EAAyC;AACrC,YAAM,KAAK6B,IAAL,CAAUqG,oBAAV,CAA+BlI,KAA/B,CAAN;AACH,KA5EmD,CA6EpD;;;AACA,QAAIsF,WAAW,IAAIF,KAAK,GAAG,KAAKhD,SAAhC,EAA2C;AACvC;AACA,WAAKkD,WAAL,CAAiB,KAAKlD,SAAtB;AACH;;AACD,SAAKA,SAAL,GAAiBgD,KAAjB;AACA,SAAK/C,QAAL,GAAgB8C,IAAhB,CAnFoD,CAoFpD;;AACA,SAAK1D,cAAL,CAAoB0G,0BAApB,CAA+ClC,MAA/C,CAAsDb,KAAK,GAAG,CAA9D;AACH;AACD;AACJ;AACA;AACA;;;AACIE,EAAAA,WAAW,CAACF,KAAD,EAAQ;AACf,SAAK3D,cAAL,CAAoBsG,eAApB,CAAoC9B,MAApC,CAA2Cb,KAA3C,EAAkD,CAAlD;AACA,SAAK3D,cAAL,CAAoB2G,cAApB,CAAmCnC,MAAnC,CAA0Cb,KAA1C,EAAiD,CAAjD;AACA,SAAK3D,cAAL,CAAoBkF,YAApB,CAAiCV,MAAjC,CAAwCb,KAAxC,EAA+C,CAA/C;AACA,SAAK3D,cAAL,CAAoBsE,OAApB,CAA4BE,MAA5B,CAAmCb,KAAnC,EAA0C,CAA1C;AACA,SAAK3D,cAAL,CAAoB4G,UAApB,CAA+BpC,MAA/B,CAAsCb,KAAK,GAAG,CAA9C,EAAiD,CAAjD;AACA,SAAK3D,cAAL,CAAoB6G,uBAApB,CAA4CrC,MAA5C,CAAmDb,KAAnD,EAA0D,CAA1D;AACA,SAAK3D,cAAL,CAAoB8G,gBAApB,CAAqCtC,MAArC,CAA4Cb,KAA5C,EAAmD,CAAnD;AACA,SAAK3D,cAAL,CAAoBuF,eAApB,CAAoCf,MAApC,CAA2Cb,KAAK,GAAG,CAAnD,EAAsD,CAAtD;AACA,SAAK3D,cAAL,CAAoB+G,YAApB,CAAiCvC,MAAjC,CAAwCb,KAAxC,EAA+C,KAAK3D,cAAL,CAAoB+G,YAApB,CAAiClC,MAAjC,GAA0ClB,KAAzF,EATe,CAUf;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACqB,QAAXmB,WAAW,CAACnB,KAAD,EAAQD,IAAR,EAAc;AAC3B,QAAIsD,QAAQ,GAAG,KAAKhH,cAAL,CAAoBsE,OAApB,CAA4BX,KAA5B,CAAf;;AACA,QAAI,CAACqD,QAAL,EAAe;AACXA,MAAAA,QAAQ,GAAG,KAAKhH,cAAL,CAAoBsE,OAApB,CAA4BX,KAA5B,IAAqC,CAAC,KAAKvD,IAAL,CAAUE,WAAV,CAAsB2G,SAAtB,EAAD,CAAhD;AACH,KAJ0B,CAK3B;;;AACA,UAAMC,WAAW,GAAG,KAAKlH,cAAL,CAAoBmH,wBAApB,CAA6CxD,KAA7C,CAApB;;AACA,QAAIuD,WAAJ,EAAiB;AACb,WAAK,MAAME,OAAX,IAAsBJ,QAAtB,EAAgC;AAC5B,cAAMK,gBAAgB,GAAG,MAAM,KAAKjH,IAAL,CAAUkH,mBAAV,CAA8B3D,KAA9B,EAAqCD,IAArC,CAA/B;AACA,cAAM6D,MAAM,GAAI,KAAKvH,cAAL,CAAoB4G,UAApB,CAA+BjD,KAA/B,KAAyC0D,gBAAgB,IAAI,CAA9D,GACT,KAAKrH,cAAL,CAAoBsE,OAApB,CAA4BX,KAAK,GAAG0D,gBAAR,GAA2B,CAAvD,CADS,GAET,CAAC,MAAM,KAAKjH,IAAL,CAAUoH,sBAAV,CAAiC9D,IAAjC,EAAuCC,KAAvC,CAAP,CAFN;;AAGA,YAAI4D,MAAJ,EAAY;AACR,eAAK,MAAME,KAAX,IAAoBF,MAApB,EAA4B;AACxB;AACA,iBAAKvH,cAAL,CAAoBkF,YAApB,CAAiCvB,KAAjC,IAA0C,IAA1C;;AACA,iBAAK,MAAM+D,aAAX,IAA4BR,WAA5B,EAAyC;AACrC,kBAAIQ,aAAa,CAACC,OAAlB,EAA2B;AACvB,qBAAK3H,cAAL,CAAoB4H,QAApB,CAA6BjE,KAA7B,EAAoC,KAAKvD,IAAL,CAAUE,WAAV,CAAsB0D,IAAtB,CAA2B0D,aAAa,CAACG,MAAzC,EAAiDH,aAAa,CAACI,SAA/D,EAA0EV,OAA1E,EAAmFK,KAAnF,CAApC;AACH,eAFD,MAGK;AACD,qBAAKzH,cAAL,CAAoB4H,QAApB,CAA6BjE,KAA7B,EAAoC,KAAKvD,IAAL,CAAUE,WAAV,CAAsB0D,IAAtB,CAA2BoD,OAA3B,EAAoCM,aAAa,CAACI,SAAlD,EAA6DJ,aAAa,CAACG,MAA3E,EAAmFJ,KAAnF,CAApC;AACH;AACJ;AACJ;AACJ,SAbD,MAcK;AACD;AACA,gBAAMM,cAAc,GAAG,KAAK/H,cAAL,CAAoBgI,8BAApB,CAAmDrE,KAAK,IAAG,MAAM,KAAKvD,IAAL,CAAUkH,mBAAV,CAA8B3D,KAA9B,EAAqCD,IAArC,CAAT,CAAL,GAA2D,CAA9G,CAAvB;;AACA,eAAK,MAAMgE,aAAX,IAA4BR,WAA5B,EAAyC;AACrC,gBAAIQ,aAAa,CAACC,OAAlB,EAA2B;AACvBI,cAAAA,cAAc,CAAC9E,IAAf,CAAoB;AAChB4E,gBAAAA,MAAM,EAAET,OADQ;AAEhBU,gBAAAA,SAAS,EAAEJ,aAAa,CAACI,SAFT;AAGhBV,gBAAAA,OAAO,EAAEM,aAAa,CAACG;AAHP,eAApB;AAKH,aAND,MAOK;AACDE,cAAAA,cAAc,CAAC9E,IAAf,CAAoB;AAChB4E,gBAAAA,MAAM,EAAEH,aAAa,CAACG,MADN;AAEhBC,gBAAAA,SAAS,EAAEJ,aAAa,CAACI,SAFT;AAGhBV,gBAAAA;AAHgB,eAApB;AAKH;AACJ;AACJ;AACJ;;AACD,WAAKpH,cAAL,CAAoBmH,wBAApB,CAA6C3C,MAA7C,CAAoDb,KAApD,EAA2D,CAA3D;AACA,WAAK3D,cAAL,CAAoB+G,YAApB,CAAiCvC,MAAjC,CAAwCb,KAAxC,EAA+C,CAA/C;AACA,WAAK3D,cAAL,CAAoB8G,gBAApB,CAAqCtC,MAArC,CAA4Cb,KAA5C,EAAmD,CAAnD;AACH,KAnD0B,CAoD3B;;;AACA,UAAMsE,WAAW,GAAG,KAAKjI,cAAL,CAAoBkI,wBAApB,CAA6CvE,KAA7C,CAApB;;AACA,QAAIsE,WAAJ,EAAiB;AACb,WAAK,MAAMb,OAAX,IAAsBJ,QAAtB,EAAgC;AAC5B;AACA;AACA;AACA,cAAMS,KAAK,GAAG9D,KAAK,KAAK,CAAV,IAAeyD,OAAO,CAACe,QAAR,KAAqB,WAApC,IACP,CAAC,KAAKnI,cAAL,CAAoBoI,kBADd,GACmC,KAAKhI,IAAL,CAAU+D,eAAV,EADnC,GACiEiD,OAD/E;AAEA,aAAKpH,cAAL,CAAoBkF,YAApB,CAAiCvB,KAAjC,IAA0C,IAA1C;;AACA,aAAK,MAAM+D,aAAX,IAA4BO,WAA5B,EAAyC;AACrC,eAAKjI,cAAL,CAAoB4H,QAApB,CAA6BjE,KAA7B,EAAoC,KAAKvD,IAAL,CAAUE,WAAV,CAAsB0D,IAAtB,CAA2B0D,aAAa,CAACN,OAAzC,EAAkDM,aAAa,CAACI,SAAhE,EAA2EJ,aAAa,CAACG,MAAzF,EAAiGJ,KAAjG,CAApC;AACH;AACJ;;AACD,WAAKzH,cAAL,CAAoBkI,wBAApB,CAA6C1D,MAA7C,CAAoDb,KAApD,EAA2D,CAA3D;AACH;AACJ;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AACqB,QAAXkC,WAAW,CAACnC,IAAD,EAAOC,KAAP,EAAc2B,UAAd,EAA0B;AACvC,SAAK,MAAMU,YAAX,IAA2BxH,YAAY,CAACyH,cAAxC,EAAwD;AACpD,UAAI,MAAMD,YAAY,CAACqC,QAAb,CAAsB,KAAKrI,cAA3B,EAA2C,KAAKI,IAAhD,EAAsDsD,IAAtD,EAA4DC,KAA5D,EAAmE2B,UAAnE,CAAV,EAA0F;AACtF,eAAO;AAAEQ,UAAAA,KAAK,EAAE,IAAT;AAAeN,UAAAA,QAAQ,EAAEF,UAAU,IAAIU,YAAY,CAACsC,iBAAb;AAAvC,SAAP;AACH;AACJ;;AACD,WAAO;AAAExC,MAAAA,KAAK,EAAE,KAAT;AAAgBN,MAAAA,QAAQ,EAAE;AAA1B,KAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACIxE,EAAAA,yBAAyB,GAAG;AACxB;AACA,SAAKT,UAAL,CAAgBgI,OAAhB,GAA2BhK,KAAD,IAAW;AACjC,YAAMoF,KAAK,GAAG,KAAKpD,UAAL,CAAgBiI,KAAhB,CAAsB3D,MAApC;AACA,YAAMnB,IAAI,GAAI,IAAI6C,KAAJ,CAAU5C,KAAK,GAAG,CAAlB,EAAqB8E,IAArB,CAA0B,CAA1B,CAAD,CAA+BC,GAA/B,CAAmC,CAACC,CAAD,EAAIlD,CAAJ,KAAU;AACtD,eAAOA,CAAC,KAAK9B,KAAN,GAAc,KAAKpD,UAAL,CAAgBqB,GAA9B,GAAoC,KAAKrB,UAAL,CAAgBiI,KAAhB,CAAsB/C,CAAtB,EAAyB7D,GAApE;AACH,OAFY,CAAb;;AAGA,UAAI,CAAC,KAAKgH,qBAAL,CAA2BjF,KAA3B,CAAL,EAAwC;AAAE;AACtC,cAAMkF,UAAU,GAAG,MAAM,KAAKpF,aAAL,CAAmBC,IAAnB,EAAyBnF,KAAzB,EAAgCoF,KAAhC,EAAuC,IAAvC,CAAzB;;AACA,YAAI,CAAC,KAAK3D,cAAL,CAAoBoC,gBAArB,IACG,CAAC,KAAKpC,cAAL,CAAoB8I,WAApB,CAAgCC,UAAhC,CAA2CrF,IAAI,CAACkB,KAAL,CAAW,CAAX,EAAc,CAAC,CAAf,CAA3C,CADR,EACuE;AACnE;AACA;AACA;AACA;AACA;AACA,cAAIlB,IAAI,CAACC,KAAD,CAAJ,KAAgB,UAApB,EAAgC;AAC5B,gBAAIqF,IAAI,GAAG,KAAKxI,WAAL,CAAiBmD,KAAjB,CAAX;;AACA,gBAAI,CAACqF,IAAL,EAAW;AACPA,cAAAA,IAAI,GAAG,KAAKxI,WAAL,CAAiBmD,KAAjB,IAA0B,EAAjC;AACH;;AACDqF,YAAAA,IAAI,CAAC/F,IAAL,CAAU4F,UAAV;AACH,WAND,MAOK,IAAInF,IAAI,CAACC,KAAD,CAAJ,KAAgB,OAAhB,IACF,OAAOD,IAAI,CAACC,KAAD,CAAX,KAAuB,QAAvB,IAAmCD,IAAI,CAACC,KAAK,GAAG,CAAT,CAAJ,KAAoB,OADzD,EACkE;AAAE;AACrE;AACA,iBAAKlD,QAAL,CAAcwC,IAAd,CAAmB;AAAEgG,cAAAA,GAAG,EAAEJ,UAAP;AAAmBnF,cAAAA,IAAI,EAAEA,IAAI,CAACkB,KAAL,CAAW,CAAX,EAAclB,IAAI,CAACmB,MAAL,GAAc,CAA5B;AAAzB,aAAnB;AACH,WAJI,MAKA;AACD,iBAAKnE,mBAAL,CAAyBuC,IAAzB,CAA8B;AAAEgG,cAAAA,GAAG,EAAEJ,UAAP;AAAmBnF,cAAAA;AAAnB,aAA9B;AACH;AACJ,SAtBD,MAuBK;AACD;AACA,eAAK7C,cAAL,GAAsB,KAAKA,cAAL,CAAoB2C,IAApB,CAAyBqF,UAAzB,CAAtB;AACH,SA5BmC,CA6BpC;;;AACA,YAAI,CAAC,KAAK7I,cAAL,CAAoBoC,gBAArB,IAAyCuB,KAAK,KAAK,CAAvD,EAA0D;AACtD,eAAK9C,cAAL,GAAsB,KAAKA,cAAL,CACjB2C,IADiB,CACZ,MAAM,KAAK0F,mBAAL,EADM,CAAtB;AAEH;AACJ;AACJ,KAxCD;;AAyCA,SAAK3I,UAAL,CAAgB4I,OAAhB,GAA2BtG,KAAD,IAAW;AACjC,WAAKE,IAAL,CAAU,OAAV,EAAmBF,KAAnB;AACH,KAFD;AAGH;AACD;AACJ;AACA;AACA;AACA;;;AACI+F,EAAAA,qBAAqB,CAACjF,KAAD,EAAQ;AACzB,SAAK,IAAI8B,CAAC,GAAG9B,KAAb,EAAoB8B,CAAC,GAAG,CAAxB,EAA2BA,CAAC,EAA5B,EAAgC;AAC5B,UAAI,KAAKlF,UAAL,CAAgBiI,KAAhB,CAAsB/C,CAAC,GAAG,CAA1B,EAA6B7D,GAA7B,KAAqC,UAAzC,EAAqD;AACjD,eAAO,IAAP;AACH;AACJ;;AACD,WAAO,KAAP;AACH;AACD;AACJ;AACA;AACA;;;AAC6B,QAAnBsH,mBAAmB,GAAG;AACxB;AACA,SAAK,MAAMF,IAAX,IAAmB,KAAKxI,WAAxB,EAAqC;AACjC,UAAIwI,IAAJ,EAAU;AACN,aAAK,MAAMC,GAAX,IAAkBD,IAAlB,EAAwB;AACpB,gBAAMC,GAAG,EAAT;AACH;AACJ;AACJ,KARuB,CASxB;;;AACA,SAAKjJ,cAAL,CAAoB0G,0BAApB,CAA+ClC,MAA/C,CAAsD,CAAtD,EAVwB,CAWxB;;AACA,SAAK,MAAMyE,GAAX,IAAkB,KAAKvI,mBAAvB,EAA4C;AACxC;AACA;AACA,UAAI,KAAKD,QAAL,CAAcoE,MAAd,GAAuB,CAA3B,EAA8B;AAC1B;AACA,cAAMuE,kBAAkB,GAAG,EAA3B;AACA,cAAMC,oBAAoB,GAAG,EAA7B;;AACA,aAAK,IAAI5D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKhF,QAAL,CAAcoE,MAAlC,EAA0CY,CAAC,EAA3C,EAA+C;AAC3C,gBAAM6D,OAAO,GAAG,KAAK7I,QAAL,CAAcgF,CAAd,CAAhB;;AACA,cAAI/F,MAAM,CAACW,IAAP,CAAYkJ,aAAZ,CAA0BD,OAAO,CAAC5F,IAAlC,EAAwCuF,GAAG,CAACvF,IAA5C,CAAJ,EAAuD;AACnD0F,YAAAA,kBAAkB,CAACnG,IAAnB,CAAwBqG,OAAxB;AACAD,YAAAA,oBAAoB,CAACpG,IAArB,CAA0BwC,CAA1B;AACH;AACJ,SAVyB,CAW1B;;;AACA,cAAM+D,cAAc,GAAGJ,kBAAkB,CAACK,IAAnB,CAAwB,CAACC,IAAD,EAAOC,IAAP,KAAgBD,IAAI,CAAChG,IAAL,CAAUmB,MAAV,GAAmB8E,IAAI,CAACjG,IAAL,CAAUmB,MAArE,CAAvB,CAZ0B,CAa1B;;AACA,aAAK,MAAMyE,OAAX,IAAsBE,cAAtB,EAAsC;AAClC,gBAAMF,OAAO,CAACL,GAAR,EAAN;AACH,SAhByB,CAiB1B;AACA;;;AACA,cAAMW,0BAA0B,GAAGP,oBAAoB,CAACI,IAArB,GAA4B9B,OAA5B,EAAnC;;AACA,aAAK,MAAMkC,KAAX,IAAoBD,0BAApB,EAAgD;AAC5C,eAAKnJ,QAAL,CAAc+D,MAAd,CAAqBqF,KAArB,EAA4B,CAA5B;AACH;AACJ;;AACD,YAAMZ,GAAG,CAACA,GAAJ,EAAN;AACH;AACJ;;AArZyC;;AAuZ9C3K,OAAO,CAACE,YAAR,GAAuBA,YAAvB;AACAA,YAAY,CAACsL,uBAAb,GAAuC,KAAvC;AACAtL,YAAY,CAACyH,cAAb,GAA8B,CAC1B,IAAIpH,wBAAwB,CAACkL,sBAA7B,EAD0B,EAE1B,IAAI9K,4BAA4B,CAAC+K,0BAAjC,EAF0B,EAG1B,IAAI7K,uBAAuB,CAAC8K,qBAA5B,EAH0B,EAI1B,IAAI7K,6BAA6B,CAAC8K,2BAAlC,EAJ0B,EAK1B,IAAIhL,0BAA0B,CAACiL,wBAA/B,EAL0B,EAM1B,IAAI9K,yBAAyB,CAAC+K,uBAA9B,EAN0B,EAO1B,IAAI9K,yBAAyB,CAAC+K,uBAA9B,EAP0B,EAQ1B,IAAI7K,0BAA0B,CAAC8K,wBAA/B,EAR0B,EAS1B,IAAIxL,uBAAuB,CAAC2F,qBAA5B,EAT0B,EAU1B,IAAIlF,oCAAoC,CAACgL,kCAAzC,EAV0B,EAW1B,IAAIvL,uBAAuB,CAACwL,qBAA5B,EAX0B,EAY1B,IAAIzL,6BAA6B,CAAC0L,2BAAlC,EAZ0B,CAA9B","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = require('jsonparse');\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst stream_1 = require(\"stream\");\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\nconst ParsingContext_1 = require(\"./ParsingContext\");\nconst Util_1 = require(\"./Util\");\nconst http_link_header_1 = require(\"http-link-header\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        // Special cases when receiving something else than the JSON-LD media type\n        if (mediaType !== 'application/ld+json') {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = http_link_header_1.parse(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        const output = new stream_1.PassThrough({ readableObjectMode: true });\n        stream.on('error', (error) => parsed.emit('error', error));\n        stream.on('data', (data) => output.push(data));\n        stream.on('end', () => output.push(null));\n        const parsed = output.pipe(new JsonLdParser(this.options));\n        return parsed;\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.emit('data', this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (this.util.isLiteral(depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        if (!subjects) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            if (bufferedValue.reverse) {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.object, bufferedValue.predicate, subject, graph));\n                            }\n                            else {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(subject, bufferedValue.predicate, bufferedValue.object, graph));\n                            }\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else if (keys[depth] === '@type'\n                        || typeof keys[depth] === 'number' && keys[depth - 1] === '@type') { // Also capture @type with array values\n                        // Remove @type from keys, because we want it to apply to parent later on\n                        this.typeJobs.push({ job: valueJobCb, keys: keys.slice(0, keys.length - 1) });\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        // Handle non-context jobs\n        for (const job of this.contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nexports.JsonLdParser = JsonLdParser;\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\n//# sourceMappingURL=JsonLdParser.js.map"]},"metadata":{},"sourceType":"script"}